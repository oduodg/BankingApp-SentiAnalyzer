# -*- coding: utf-8 -*-
"""품사별 빈도수 살펴보기.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1fz6NaCQ9VGE_sxCoD5Ks1nspHeSKpmYZ

# 1. 코랩 환경 설정
"""

from google.colab import drive
drive.mount('/content/drive')

# Commented out IPython magic to ensure Python compatibility.
# 디렉토리 변경
# %cd drive/MyDrive/PBL

# 현재 디렉토리 경로 확인
!pwd

"""# 2. 형태소 분석"""

pip install PyKomoran

pip install tqdm

import pandas as pd
from PyKomoran import *
import sys
import regex
import warnings 
import copy
from tqdm import tqdm 
import time
warnings.filterwarnings('ignore')

"""## 사용자 정의 사전 등록"""

# STABLE or EXP
komoran = Komoran("EXP")
#komoran.set_user_dic("user_dictionary.txt")  #사용자 정의 사전 등록

"""## 분석데이터 불러오기"""

#분석할 리뷰들이 담겨져 있는 데이터 프레임 불러오기
all_reviews = pd.read_csv("/content/drive/Shareddrives/언어의미와정보 데이터캡스톤디자인/리뷰 데이터/spell_checked/city_spell_checked.csv")
all_reviews.head()

#2021년 리뷰만 뽑기(어플은 업데이트를 통해서 계속 변하기 때문에 오래된 리뷰는 신뢰할 수 없다고 판단!)
koreanCity_review2021 = koreanCity_review[koreanCity_review['date'].str.contains('2021')]
koreanCity_review2021.tail()

#userName 삭제
koreanCity_review2021 = koreanCity_review2021.drop(['userName'], axis = 'columns')
koreanCity_review2021.columns

all_reviews.head()

all_reviews.tail()



"""## 코드 함수화"""

## Seperator_part(한문장)
##한 문장에 대해 형태소 분석하고 (단어, 품사) 형태로 결과를 리턴해주는 함수

def Seperator_part(oneL):
  slash_line = komoran.get_list(oneL)

  # (단어,품사) 형태로 만들기
  tagged_list = []
  for i in range(len(slash_line)):
      a = str(slash_line[i]).split('/')
      tagged_list.append(a)

  for j in tagged_list:
      if len(j) != 2:
          tagged_list.remove(j)

  return tagged_list

## Tag_list(리스트)
## 리뷰가 담겨있는 리스트를 넣었을 때 리뷰들을 한줄로 바꾸어서 형태소 분석하고 그 결과를 리턴해주는 함수
## 특정 품사가 전체 리뷰에서 몇번 나왔는지 파악할 때 용이

def Tag_list(review_list):
  # 필터 설정
  mask = '\\n|\\t|\\r,'

  one_line = "".join(review_list)  #리스트 속에 개별 원소로 들어가 있는 리뷰들을 한 줄로 합침
  one_line = regex.sub(mask,'',one_line)

  return Seperator_part(one_line)



"""## 특정 품사 단어 빈도수 계산해서 저장하는 함수 정의"""

## cal_count(품사, 단어-품사 형태로 저장된 형태소분석 결과 리스트)
## 해당 품사의 단어들을 빈도수 높은 순 부터 저장된 데이터프레임 반환
def cal_count(pumsa, tag_ls):
  # 품사에 해당하는 단어들 리스트에 담음
  ls = []
  for i in range(len(tag_ls)):
    if ((tag_ls[i][1] == pumsa)):
      ls.append(tag_ls[i][0])
  
  #빈도 계산 쉽도록 데이터프레임으로 저장
  count_df = pd.DataFrame({pumsa:ls})
  count_df= count_df.value_counts().rename_axis(pumsa).reset_index(name='counts')
  return count_df

#Tag_list(한국시티어플리뷰리스트) 결과
tagged_list = Tag_list(all_reviews['comment'])

"""- 품사 빈도수 csv파일 저장"""

for p in ['VA', 'VV', 'MAG', 'VCP', 'VCN', 'NR', 'IC', 'XR', 'VX']:
  count_df = cal_count(p, tagged_list)
  #count_df.to_csv(+p+'단어빈도수.csv')

"""- 빈도수 시각화"""

NNG_word = cal_count('NNG', tagged_list)
NNP_word = cal_count('NNP', tagged_list)
VA_word = cal_count('VA', tagged_list)
VV_word = cal_count('VV', tagged_list)
MAG_word = cal_count('MAG', tagged_list)
VCP_word = cal_count('VCP', tagged_list)
VCN_word = cal_count('VCN', tagged_list)
NR_word = cal_count('NR', tagged_list)
IC_word = cal_count('IC', tagged_list)
XR_word = cal_count('XR', tagged_list)
VX_word = cal_count('VX', tagged_list)

import matplotlib.pyplot as plt
plt.plot(list(range(len(NNG_word))), NNG_word['counts'])
plt.show()

